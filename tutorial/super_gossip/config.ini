[DATASET]
dataset_package = decentralizepy.datasets.CIFAR10
dataset_class = CIFAR10
model_class = LeNet
; provide directory containing "cifar-10-batches-py" folder | Pre-download recommended
; New download does not work with multiple processes | Crashes the first time, just retry
train_dir = /mnt/nfs/shared/CIFAR
test_dir = /mnt/nfs/shared/CIFAR
; python list of fractions below
sizes = 
random_seed = 27
partition_niid = iid
; shards = 2

[OPTIMIZER_PARAMS]
optimizer_package = torch.optim
optimizer_class = SGD
lr = 0.1

[TRAIN_PARAMS]
training_package = decentralizepy.training.Training
training_class = Training
rounds = 10
full_epochs = False
batch_size = 8
shuffle = True
loss_package = torch.nn
loss_class = CrossEntropyLoss

[COMMUNICATION]
comm_package = decentralizepy.communication.TCP
comm_class = TCP
addresses_filepath = ../../eval/data/ip.json
offset = 3500

[SHARING]
sharing_package = asyncNodes.sharing.GossipSharing
sharing_class = GossipSharing

[ASYNC_PARAMS]
training_time = 240
eval_on_train_set = False
eval_on_test_set = False
